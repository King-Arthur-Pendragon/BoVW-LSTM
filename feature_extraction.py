"""

//[]------------------------------------------------------------------------[]
//|                                                                          |
//|                         Feature Extraction Module                        |
//|                               Version 1.0                                |
//|                                                                          |
//|              Copyright 2015-2020, Marcos Vinicius Teixeira               |
//|                          All Rights Reserved.                            |
//|                                                                          |
//[]------------------------------------------------------------------------[]
//
//  OVERVIEW: feature_extraction.py
//  ================================
//  This module have the goal of generate histograms of a video sequence based
//  in codebook of visual words of a dataset pre-defined. The inputs are :
//
//      - path to dataset folder , where we'll compute the codebook (if doesn't 
//   exists already). This folder must have the following form:
            
            |-- path_to_dataset
            |    |-- class1
            |    |-- class2
            |    |-- class3
            ...
            |    |--- classN
//       where each class(i) contains a group of images belonging to class(i)
//      - path to folder of input video sequences(frames). This folder must 
//  have the following form:

            |-- path_to_folders_of_video_input
            |    |-- frame-0
            |    |-- frame-1
            |    |-- frame-2
            ...
            |    |-- frame-N  
//  Supossing that we get len(codebook) == 100, in other words, we compute 100 
//  visual words at our dataset of images and we'll generate a histogram of   
//  100 visual words for each frame of the video. The result this program is a
//  file that represents the histogram of each frame. This file is saved into
//  the folder containing the video frames sequence.
    

// Parameters:
// sys.argv[1] => dataset path
// sys.argv[2] => input folder video sequence

"""

from os.path import exists, isdir, basename, isfile, join, splitext
import sift
from glob import glob
from numpy import zeros, resize, sqrt, histogram, hstack, vstack, savetxt, zeros_like, fromstring, asarray
import scipy.cluster.vq as vq
import matplotlib.pyplot as plt
from cPickle import dump, HIGHEST_PROTOCOL
import argparse
import sys
# extentions for image files ..
EXTENSIONS = [".jpg", ".bmp", ".png", ".pgm", ".tif", ".tiff"]
DATASETPATH = '../dataset'
PRE_ALLOCATION_BUFFER = 1000  # for sift
# name of file where will be saved the histograms of visual words for each frame 
HISTOGRAMS_FILE = 'trainingdata.lstm'
# threshold for early stopping kmeans 
K_THRESH = 1 
# name of the codebook file
CODEBOOK_FILE = 'codebook.txt'

# extracting the class names given a folder name (dataset)
def get_classes(datasetpath):
    cat_paths = [files
                 for files in glob(datasetpath + "/*")
                  if isdir(files)]

    cat_paths.sort()
    cats = [basename(cat_path) for cat_path in cat_paths]

    return cats

# getting the array of files(images) inside a given folder
def get_imgfiles(path):
    all_files = []

    all_files.extend([join(path, basename(fname))
                    for fname in glob(path + "/*")
                    if splitext(fname)[-1].lower() in EXTENSIONS])
    return all_files

# calculate the sift descriptor for each image of a input array. The output
# is saved with the same name of image file plus '.sift'
def extractSift(input_files):
    print "extracting Sift features"
    all_features_dict = {}

    for i, fname in enumerate(input_files):
        features_fname = fname + '.sift'

        if exists(features_fname) == False:
            print "calculating sift features for", fname
            sift.process_image(fname, features_fname)

        print "gathering sift features for", fname,
        locs, descriptors = sift.read_features_from_file(features_fname)
        print descriptors.shape
        all_features_dict[fname] = descriptors

    return all_features_dict

# transforming a dict in a numpy array
# ...
def dict2numpy(dict):
    nkeys = len(dict)
    array = zeros((nkeys * PRE_ALLOCATION_BUFFER, 128))
    pivot = 0
    for key in dict.keys():
        value = dict[key]
        nelements = value.shape[0]
        while pivot + nelements > array.shape[0]:
            padding = zeros_like(array)
            array = vstack((array, padding))
        array[pivot:pivot + nelements] = value
        pivot += nelements
    array = resize(array, (pivot, 128))
    return array

# calculating histograms given a codebook that represents the vocabulary and
# the array of descriptors, generated by each image
def computeHistograms(codebook, descriptors):
    code, dist = vq.vq(descriptors, codebook)
    histogram_of_words, bin_edges = histogram(code,
                                              bins=range(codebook.shape[0] + 1),
                                              normed=True)
    return histogram_of_words

# writing the histograms into the file 
def writeHistogramsToFile(nwords, fnames, all_word_histgrams, features_fname):
    data_rows = zeros(nwords + 1)  # +1 for the category label

    for fname in fnames:
        histogram = all_word_histgrams[fname]

        if (histogram.shape[0] != nwords):  # scipy deletes empty clusters
            nwords = histogram.shape[0]
            data_rows = zeros(nwords + 1)
        
        data_row = hstack((0, histogram))
        data_rows = vstack((data_rows, data_row))
    
    data_rows = data_rows[1:]
    fmt = '%i '
    for i in range(nwords):
        fmt = fmt + str(i) + ':%f '
    
    savetxt(features_fname, data_rows, fmt)


# passing the codebook of string to numpy array
def stringToNumpy(codebook_file):
    codebook = []

    lines = codebook_file.readlines()

    for line in lines:
        line_array = fromstring(line,dtype=float,sep=' ')
        codebook.append(line_array)

    return asarray(codebook)

if __name__ == '__main__':
    codebook_exists = False

    print "Parsing params"
    datasetpath = sys.argv[1]

    cats = get_classes(datasetpath)
    ncats = len(cats)
    print "searching for folders at " + datasetpath
    if ncats < 1:
        print"Wrong path! \n"
        exit(1)

    # checking if already exist a codebook. If not, create a new codebook.
    # ...
    if isfile(datasetpath + '/' + CODEBOOK_FILE):
        codebook_exists = True
        print "Already exist a codebook. Using him"
        content_file = open(datasetpath + '/' + CODEBOOK_FILE, 'r')
        codebook = stringToNumpy(content_file)
    else:   
        all_files = []
        all_files_labels = {}
        
        # Obs,: all_features is a dict of form: 'image-path' : 'descriptor'
        all_features = {}
        cat_label = {}

        for cat, label in zip(cats, range(ncats)):
            # path of class
            cat_path = join(datasetpath, cat)
            # name of each image file
            cat_files = get_imgfiles(cat_path)
            # extracting features
            cat_features = extractSift(cat_files)
            all_files = all_files + cat_files
            # appending more features
            all_features.update(cat_features)
            cat_label[cat] = label
            for i in cat_files:   
                all_files_labels[i] = label

        print "computing the visual words via k-means"
        # passing to numpy array
        all_features_array = dict2numpy(all_features)
        # number of features
        nfeatures = all_features_array.shape[0]
        # number of clusters
        nclusters = int(sqrt(nfeatures))
        
        codebook, distortion = vq.kmeans(all_features_array,
                                                 nclusters,
                                                 thresh=K_THRESH)
        print "writing the codebook in file "
        f = open(datasetpath + CODEBOOK_FILE, 'wb')
        savetxt(f,codebook)

    # test in a new sequence of video frames
    print "Starting to generate histograms to video.."
    # taking the video folder name
    
    if not exists(sys.argv[2] + '/' + sys.argv[3]):
    	print "This path doesn't exist!"
    	exit(1)
    
    videofolder = sys.argv[3]
    
    test_files = []
    test_features = {}
    test_frames_labels = {}

    testfolder_path = join(sys.argv[2], videofolder)

    test_files = get_imgfiles(testfolder_path)
    # extracting features
    feats = extractSift(test_files)

    test_features.update(feats)

    # Generate the histograms based on codebook pre-processed (for all frames of the video )
    histograms = {}
    for imagefname in test_features:
        visual_histogram = computeHistograms(codebook, test_features[imagefname])
        histograms[imagefname] = visual_histogram

    # print "writing histograms to file"
    if not codebook_exists:
        number_of_words = nclusters
        writeHistogramsToFile(number_of_words,
                              test_files,
                              histograms,
                              sys.argv[2] + HISTOGRAMS_FILE)
    else:
        number_of_words = len(content_file.readlines())
        writeHistogramsToFile(number_of_words,
                              test_files,
                              histograms,
                              sys.argv[2] + HISTOGRAMS_FILE)

    # .. plotting the histograms

    #for imageName in test_features:
    #    plt.hist(histograms[imageName])
    #    plt.title("Gaussian Histogram")
    #    plt.xlabel("Value")
    #    plt.ylabel("Frequency")
    #    plt.show()

